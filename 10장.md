## 클러스터

### 레디스 클러스터와 확장성
+ 스케일 업 vs 스케일 아웃
    - 확장성은 운영 중인 시스템에서 증가하는 트래픽에 유연하게 대응할 수 있는 능력
    - 사용자가 데이터의 증가로 시스템이 처리할 수 있는 트래픽이 많아지면 시스템의 확장이 필요
        + 스케일 업
            - 단일 서버의 하드웨어 사양을 업그레이드하여 성능을 향상시키는 방법
            - 기존 서버에 더 많은 CPU, RAM, 스토리지 등을 추가
                + 특징
                    - 하나의 서버 내에서 리소스 증설
                    - 애플리케이션 아키텍처 변경이 불필요
                    - 설정과 관리가 상대적으로 단순
                + 장점
                    - 구현이 간단하고 즉시 효과를 볼 수 있음
                    - 기존 소프트웨어와 호환성 유지
                    - 네트워크 지연이나 데이터 일관성 문제없음
                    - 단일 장애점이지만 관리 복잡도가 낮음
                + 한계
                    - 하드웨어 업그레이드의 물리적 한계
                    - 비용이 기하급수적으로 증가
                    - 단일 실패점
                    - 업그레이드 시 다운타임 발생
        + 스케일 아웃
            - 여러 대의 서버를 추구하여 시스템 전체의 처리 능력을 향상시키는 방법
            - 부하를 여러 서버에 분산시켜 처리
                + 특징
                    - 서버 대수 증가를 통한 성능 향상
                    - 분산 아키텍처 설계 필요
                    - 로드 밸런싱과 데이터 분산 기술 활용
                + 장점
                    - 이론적으로 무제한 확장 가능
                    - 선형적 비용 증가(서버 대수에 비례해서 비용이 일정하게 증가)
                    - 고가용성 확보(부분 장애 발생에도 서비스 지속)
                    - 점진적 확장 가능
                + 한계
                    - 복잡한 분산 시스템 설계 필요
                    - 네트워크 지연과 통신 오버헤드
                    - 데이터 일관성과 동기화 문제
                    - 디버깅과 모니터링의 복잡성

+ 레디스에서의 확장성
    - 레디스에서 키의 이빅션이 자주 발생한다면 서버의 메모리를 증가시키는 스케일 업을 고려할 수 있다
        + 이빅션 : maxmemory 설정값에 도달했을 때, 새로운 키를 저장하기 위해 기존 키를 삭제하는 것
    - 레디스는 단일 스레드로 동작하므로 서버에 CPU를 추가하더라도 여러 CPU 코어를 활용할 수 없다
        + 그러나 데이터를 여러 서버로 분할하여 관리하면 다수의 서버에서 요청을 병렬로 처리가 가능하므로 처리량을 확장 가능하다

+ 레디스 클러스터의 기능
    - 레디스를 클러스터 모드로 활용하면 추가적은 애플리케이션 아키텍처의 변경없이 여러 레디스 인스턴스 간의 수평 확장이 가능하다
    - 데이터의 분산 처리와 복제, 자동 페일오버도 가능하다
    - 데이터 샤딩
        + 하나의 레디스 인스턴스에 모든 데이터를 저장하지 않고 여러 인스턴스(노드)로 데이터를 나누어 저장하는 방법
        + 왜 샤딩이 필요할까
            - 메모리 한계 : 레디스는 인메모리 데이터베이스라 단일 서버의 RAM 한계를 넘을 수 없음
            - 성능 확장 : 요청을 여러 노드에 분산하면 처리량(QPS)를 늘릴 수 있음
            - 가용성 확보 : 일부 노드에 장애가 생겨도 전체 데이터가 날아가는 것을 막을 수 있음
        + 레디스의 샤딩 방식
            - 애플리케이션 레벨 샤딩
                + 애플리케이션에서 직접 샤드를 결정하는 방식
                + 장점
                    - 구현이 단순
                    - 완전한 제어 가능
                    - 오버헤드가 낮음
                + 단점
                    - 샤드 추가/제거 시 대규모 데이터 재배치 필요
                    - 애플리케이션 복잡성 증가
                    - 장애 처리를 직접 구현해야 함
            - 프록시 기반 샤딩
                + 중간 프록시 서버가 샤딩을 담당하는 방식
                + 장점
                    - 애플리케이션 변경 최소화
                    - 일관된 해싱으로 재배치 최소화
                    - 중앙화된 관리
                + 단점
                    - 단일 실패점 가능성
                    - 프록시 성능이 병목될 수 있음
            - 레디스 클러스터
                + 레디스에서 지원하는 분산방식
    - 고가용성
        + 클러스터는 각각 3대의 마스터, 슬레이브로 총 6대로 구성하는 것이 일반적
            - 왜 3/3대로 구성해야하나?
                + 슬레이브는 구성할 필요가 없지만 마스터는 최소 3대로 구성해야 함
                + 과반수 원칙
                    - 2대로는 장애시 결정을 내릴 수 없음
                    - 3대면 1대가 장애여도 2/3으로 과반수 동작 가능
                + 마스터만 구성(고가용성 없음)
                    - 데이터 분산은 가능
                    - 마스터 장애시 해당 노드의 데이터 접근 불가(슬레이브가 없어 페일오버가 불가능하므로)
                    - 페일오버 불가능
        + 하나의 클러스터 구성에 속한 각 노드는 서로를 모니터링
            - 마스터 노드에 장애가 발생하면 다른 마스터 노드들이 장애가 발생한 마스터의 복제본 노드를 마스터로 자동 페일오버
            - 레디스 클러스터들은 클러스터 버스라는 전용 네트워크 채널을 통해 통신한다
                ```bash
                6379/tcp    # 레디스 노드 포트
                16379/tcp   # 클러스터 버스 포트
                # 일반포트에서 +10000을 더한 포트로 자동 설정
                ```
                + 클러스터 버스의 역할
                    - 노드 발견과 상태 관리
                        + 새 노드가 클러스터에 조인
                    - 가십 프로토콜
                    - 장애 감지
                    - 슬롯 할당 정보 동기화
                    - 페일오버 조정

### 레디스 클러스터 동작 확인
+ 해시슬롯을 이용한 데이터 샤딩
    - 클러스터 구조에서 모든 데이터는 해시 슬롯에 저장
        + 레디스는 총 16384개의 해시 슬롯을 가지고 키를 균등하게 분배하는 방식
        + 왜 16384개의 해시 슬롯으로 구성되었나
            - 각 노드가 슬롯 매핑 정보를 메모리에 저장하는데 2KB 메모리를 비트맵으로 관리하면 1 또는 0으로 내가 담당인지 다른 노드가 담당인지 빠르게 판단이 가능
            - 장점
                + 메모리 사용량
                ```bash
                16384 비트 / 8 = 2048바이트 = 2KB

                # CPU 캐시 친화적
                L1 캐시(32kb에)에 여러번 저장가능
                ```
                + 네트워크 효율성
                    - 가십 프로토콜에서 슬롯 정보 전송
                    - PING에 2KB 비트맵 포함
    - CRC16 해시 함수를 사용하여 해시 슬롯에 저장
        ```bash
        # 키 → 슬롯 계산 공식
        슬롯 번호 = CRC16(키) mod 16384

        # 실제 예시
        CRC16("user:1000") = 31339
        31339 mod 16384 = 14955
        → "user:1000"은 슬롯 14955에 저장
        ```
    - 해시태그
        + 클러스터를 사용할 때는 다중 키 커맨드를 사용할 수 없다
            - 서로 다른 해시 슬롯에 데이터가 저장되어 있으므로
            - 왜 안되냐
                + 클러스터는 키를 확인해 키가 속해있는 마스터로 클라이언트의 연결을 리디렉션하므로 한번에 2개의 마스터를 연결할 수 없다
        + 해시태그를 사용하면 같은 마스터에 키를 저장할 수 있다
            ```bash
            # 문제: 서로 다른 슬롯에 배치
            SET user:1000:profile "data1"    # 슬롯 14955
            SET user:1000:settings "data2"   # 슬롯 5540
            # MGET 불가능!

            # 해결: 해시 태그 사용
            SET user:{1000}:profile "data1"   # {1000} 부분만 해싱
            SET user:{1000}:settings "data2"  # 같은 슬롯에 배치!
            ```

            |키|해시되는 값|
            |---|---|
            |{user1000}.followers|user1000|
            |user{}id|user{}id|
            |user{{name}}id|{name|
            |user{name}{id}|name|
        + 너무 많은 키가 해시태그를 가지고 있다면 하나의 해시 슬롯에 데이터가 몰리는 현상이 발생할 수 있으므로 키 분배에 대한 모니터링이 필요할 수 있다
    - 자동 재구성
        + 센티널과 마찬가지로 클러스터도 복제와 자동 페일오버를 통한 고가용성 확보가능
            - 센티널은 센티널 인스턴스를 추가로 띄우고 센티널 인스턴스가 레디스 노드를 감시하는 구조라면
            - 클러스터는 일반 레디스 노드가 서로를 감시
        + 자동 페일오버
            - 마스터에 장애가 발생하면 해당 마스터에 속한 복제본은 다른 마스터에게 페일오버 투표를 요청한다
            - 다른 마스터들은 장애가 발생한 마스터가 정상이 아니라 판단하면 복제본에게 투표를 진행하며 과반수 이상의 투표를 받은 복제본은 마스터로 승격한다
            - 이때 마스터로 승격한 복제본도 장애가 발생한다면 어떻게 될까?
                + cluster-require-full-coverage
                    - 기본값 yes
                    - 해당 커맨드로 인해 클러스터 내의 마스터가 하나라도 정상이 아닐 경우, 전체 클러스터를 사용할 수 없다
                        + 클러스터 내부의 일부 해시 슬롯을 사용할 수 없더라도 데이터 정합성을 위해 전체 클러스터를 차단한다
                    - yes로 설정했을 떄
                        + 장점
                            - 데이터 일관성 보장
                            - 명확한 장애 감지
                            - 애플리케이션 버그 방지
                        + 단점
                            - 부분 장애가 발생해도 전체 서비스 중단
                            - 가용성 저하
                    - no로 설정했을 때
                        + 장점
                            - 부분 서비스 유지
                            - 고가용성 유지
                        + 단점
                            - 일부 데이터 유실 위험
                            - 애플리케이션 복잡성 증가
                    - 부분 장애시 전체 서비스를 보호할 것인가 vs 가용성을 우선할 것인가의 정책적 선택
        + 자동 복제본 마이그레이션
            - 복제본 마이그레이션이 필요한 상황
                ```bash
                # 초기 상태 (각 마스터마다 1개 슬레이브)
                마스터A ← 슬레이브A1
                마스터B ← 슬레이브B1  
                마스터C ← 슬레이브C1

                # 슬레이브A1 장애 발생
                마스터A (복제본 없음) ← 고아 마스터!
                마스터B ← 슬레이브B1
                마스터C ← 슬레이브C1

                # 이제 마스터A 장애 시 페일오버 불가능
                ```
            - 자동 복제본 마이그레이션 조건
                + 복제본이 없는 마스터 존재
                + 여분 복제본 존재 : 다른 마스터에 2개 이상의 복제본이 있을 때
            - cluster-allow-replica-migration
                + 마이그레이션 기능 활성화/비활성화
                + 기본값은 yes
            - cluster-migration-barrier
                + 마이그레이션 임계값
                ```bash
                # cluster-migration-barrier: 1 (기본값)
                # 마스터가 최소 2개 복제본을 가져야 마이그레이션 허용
                # (1개는 유지, 1개는 마이그레이션 가능)

                # cluster-migration-barrier: 2  
                # 마스터가 최소 3개 복제본을 가져야 마이그레이션 허용
                ```

### 레디스 클러스터 실행하기
+ 클러스터 초기화
    - redis.conf에서 cluster-enabled 설정을 yes로 변경
        ```bash
        redis-cli -cluster create [host:port] --cluster-replicas 1
        ```
        + --cluster create 옵션으로 클러스터 생성을 명시
        + [host:port]에 클러스터에 추가할 레디스의 ip:port 쌍을 나열
        + --cluster-replicas 1 옵션은 각 마스터마다 1개의 복제본을 추가할 것을 의미

+ 클러스터 상태 확인하기
    - cluster nodes 커맨드로 클러스터의 상태를 확인할 수 있다
        + 해당 커맨드는 클러스터 내의 노드를 무작위로 순서없이 출력한다
            ```bash
            <id> <ip:port@cport> <flags> <master> <ping-sent> <pong-recv> <config-epoch> <link-state> <slot> ...
            ```

            |핃드명|설명|
            |---|---|
            |id|노드가 생성될 때, 자동으로 생성되는 클러스터 ID, 한번 할당된 ID는 변경되지 않음|
            |ip:port@cport|노드가 실행되는 ip와 port, 클러스터 버스 port<br/>클러스터 버스의 port는 지정하지 않으면 레디스 port에 10000을 더한 값으로 자동으로 설정|
            |flags|노드의 상태<br/>myself : redis-cli를 사용해 접근한 노드<br/>master/slave : 마스터 노드/복제본 노드<br/>fail? : 노드가 pfail 상태임을 의미<br/>fail : 노드가 fail 상태<br/>handshake : 새로운 노드를 인지하고 핸드쉐이킹하는 단계<br/>nofailover : 복제본 노드가 페일오버를 실행하지 않음<br/>noaddr : 해당 노드의 주소를 모른다는 의미<br/>noflags|
            |master|복제본 노드일 경우, 마스터 노드의 ID, 마스터 노드면 - 표기|
            |ping-sent|수신 대기 중인 ping이 없으면 0, 있으면 해당 유닉스 타임에 보낸 ping을 기다리는 상태|
            |pong-sent|마지막 pong을 수신한 유닉스 타임|
            |config-epoch|현재 노드의 에포크 값|
            |link-state|클러스터 버스에 사용되는 링크의 상태<br/>connected/disconnected|
            |slot|노드가 갖고 있는 해시 슬롯의 범위|

+ redis-cli를 이용해 클러스터 접근하기와 리디렉션
    - redis-cli (기본모드)
        + 클러스터 인식 X
            ```bash
            # 일반 redis-cli로 클러스터 접속
            redis-cli -h 192.168.1.10 -p 6379

            # 잘못된 노드에 키 요청 시 에러만 출력
            127.0.0.1:6379> GET user:12345
            (error) MOVED 9842 192.168.1.11:6379

            # 사용자가 직접 올바른 노드로 이동해야 함
            127.0.0.1:6379> exit
            redis-cli -h 192.168.1.11 -p 6379
            127.0.0.1:6379> GET user:12345
            "Alice"
            ```
        + 수동 처리가 필요
            ```bash
            # 각 명령마다 올바른 노드 찾아서 실행
            redis-cli -h 노드1 GET key1  # key1이 노드1에 없으면 MOVED 에러
            redis-cli -h 노드2 GET key1  # 수동으로 노드2 시도
            redis-cli -h 노드3 GET key1  # 찾을 때까지 반복
            ```
    - redis-cli-c (클러스터 모드)
        + 자동 리디렉션
            ```bash
            # 클러스터 모드로 접속
            redis-cli -c -h 192.168.1.10 -p 6379

            # 자동으로 올바른 노드로 이동
            127.0.0.1:6379> GET user:12345
            -> Redirected to slot [9842] located at 127.0.0.1:6380
            "Alice"

            # 클라이언트가 자동으로 127.0.0.1:6380으로 연결 변경됨
            127.0.0.1:6380> GET another_key
            -> Redirected to slot [1234] located at 
            127.0.0.1:6381  
            "Bob"

            # 사용자는 클러스터를 의식하지 않고 사용 가능
            127.0.0.1:6379> SET user:1000 "Alice"
            -> Redirected to slot [1535] located at 127.0.0.1:6380
            OK

            127.0.0.1:6380> SET user:2000 "Bob"  
            -> Redirected to slot [8025] located at 127.0.0.1:6381
            OK

            127.0.0.1:6381> GET user:1000
            -> Redirected to slot [1535] located at 127.0.0.1:6380
            "Alice"
            ```
    - 페일오버 테스트
        + 수동 페일오버
            - cluster failover 커맨드를 사용하여 수동으로 페일오버를 발생할 수 있다
            - 진행과정
                ```bash
                1. 복제 지연 확인 (slave_lag < 5초)
                2. 마스터에게 페일오버 승인 요청
                3. 마스터의 클라이언트 차단
                4. 최종 동기화 완료
                5. 다른 마스터들 투표
                6. 승격 및 서비스 재개
                ```
        + 자동 페일오버
            - 복제본 노드는 redis.conf에서 지정한 cluster-node-timeout 시간동안 마스터에서 응답이 오지않으면 마스터의 상태라 정상적이지 않다고 판단, 페일오버를 트리거한다
        + 수동 vs 자동 페일오버 비교
            - 자동 페일오버
                ```bash
                # 장애 감지 → 투표 → 승격
                소요시간: 15-30초 (cluster-node-timeout 설정값)
                트리거: 마스터 노드 장애/무응답
                안전성: 높음 (충분한 검증 시간)
                ```
            - 수동 페일오버
                ```bash
                # 즉시 실행 → 빠른 완료
                소요시간: 1-3초
                트리거: 운영자 명령
                안전성: 매우 높음 (사전 동기화)
                ```

### 레디스 클러스터 운영하기
+ 클러스터 리샤딩(수동)
    - 클러스터의 슬롯 분배를 재조정하여 노드 간 부하를 분산시키거나 클러스터의 규모를 확장/축소하는 작업
    - 리샤딩이 필요한 상황
        + 노드 추가시
            ```bash
            # 기존 3노드 클러스터
            노드A: 슬롯 0-5460     (5,461개)
            노드B: 슬롯 5461-10922 (5,462개)
            노드C: 슬롯 10923-16383 (5,461개)

            # 4번째 노드 추가 후
            노드D: 슬롯 없음 (0개) ← 리샤딩 필요!
            ```
        + 노드 제거시
            ```bash
            # 노드B를 제거하려는 경우
            노드B: 슬롯 5461-10922 (5,462개) ← 다른 노드로 이동 필요
            ```
        + 부하 불균형 해결
            ```bash
            # 불균등한 상황
            노드A: 슬롯 1,000개 (과부하)
            노드B: 슬롯 8,000개 (과부하)  
            노드C: 슬롯 7,384개 (여유)

            # 균등하게 재분배 필요
            ```
    - 클러스터 리샤딩 시작
        ```bash
        # 기본 리샤딩 명령
        redis-cli --cluster reshard 192.168.1.10:6379

        # 대화형 모드로 진행
        How many slots do you want to move (from 1 to 16384)? 1000
        What is the receiving node ID? [대상 노드 ID]
        Source node #1: [소스 노드 ID 또는 'all']
        Do you want to proceed with the proposed reshard plan (yes/no)? yes
        ```
        + all을 입력하면 모든 마스터 노드
        + 특정 마스터 노드만 지정하고 싶으면 마스터 노드의 ID를 입력 후, done
    - 클러스터 리샤딩 결과 확인
        + redis-cli --cluster check 커맨드로 확인 가능
            ```bash
            # 정상적인 출력 예시
            192.168.1.10:6379 (abc123...) -> 5461 keys | 5461 slots | 1 slaves.
            192.168.1.11:6379 (def456...) -> 5462 keys | 5462 slots | 1 slaves.
            192.168.1.12:6379 (ghi789...) -> 5461 keys | 5461 slots | 1 slaves.
            [OK] All 16384 slots covered.

            # 문제상황 출력
            # 일부 슬롯 미할당
            # 192.168.1.10 노드에 복제본 없음
            # 192.168.1.12 노드에 할당된 슬롯없음
            192.168.1.10:6379 (abc123...) -> 1000 keys | 5461 slots | 0 slaves.
            192.168.1.11:6379 (def456...) -> 1500 keys | 5462 slots | 1 slaves.
            192.168.1.12:6379 (ghi789...) -> 0 keys | 0 slots | 0 slaves.

            [ERR] Not all 16384 slots are covered by nodes.
            [ERR] Node 192.168.1.10:6379 has no replicas.
            ```

+ 클러스터 리샤딩(간단 버전)
    - 클러스터 리샤딩을 스크립트로 진행하는 방법도 존재한다
    - 커맨드를 실행하자마자 데이터가 전달되기 떄문에 중간에 취소와 확인이 어렵다
        ```bash
        redis-cli --cluster reshard <host>:<port> --cluster-from <node-id>
        --cluster-to <node-id> --cluster-slots <number of slots> --cluster-yes
        ```
        + --cluster-yes 커맨드는 모든 프롬프트에 자동으로 yes를 입력하겠다는 의미

+ 클러스터 확장
    - 클러스터에 노드를 추가할 때, 데이터가 존재하는 노드도 추가가 가능
        ```bash
        redis-cli --cluster add-node 192.168.1.14:6379 192.168.1.10:6379

        # 출력:
        [ERR] Node 192.168.1.14:6379 is not empty. 
        Either the node already knows other nodes (check with CLUSTER NODES) 
        or contains some key in database 0.
        ```
        + 노드에 이미 데이터가 존재할 때
            - 클러스터에 추가가 가능
            - 다만 리샤딩을 통한 슬롯 할당을 받지못하여 데이터에 접근이 불가
        + 노드가 이미 클러스터에 추가되어 있거나
    - 클러스터 노드 추가
        + 마스터 노드로 추가하기
            ```bash
            redis-cli --cluster add-node <추가할 노드 IP:PORT> <기존 노드 IP:PORT>
            ``` 
        + 복제본으로 추가하기
            ```bash
            redis-cli --cluster add-node <추가할 노드 IP:PORT> <기존 노드 IP:PORT> --cluster-slave [--cluster-master-id <기존 마스터 ID>]
            ```
            - 마스터 노드를 추가하는 커맨드와 동일하며 끝에 --cluster-slave 옵션이 추가된다
            - --cluster-master-id 옵션을 추가하지 않으면 임의의 마스터 노드의 복제본으로 연결된다
                + 복제본이 대칭적인 구조가 아닌 경우, 보유한 복제본이 제일 적은 마스터의 복제본으로 연결됨
    - 클러스터 노드 제거하기
        ```bash
        redis-cli --cluster del-node <기존 노드 IP:PORT> <삭제할 노드 ID>
        ```
        + 제거하려는 노드가 마스터, 복제본 구별하지 않고 삭제
            - 삭제하려는 노드에 할당된 슬롯이 있으면 삭제가 안된다
                + 리샤딩으로 데이터를 이동시키고 삭제
        + cluster forget
            - 노드를 클러스터에서 제외시키는 커맨드
                ```bash
                redis-cli -h <노드 A> cluster forget <노드 B ID>

                # 초기 클러스터 상태
                노드A: 노드B, 노드C, 노드D를 알고 있음
                노드B: 노드A, 노드C, 노드D를 알고 있음
                노드C: 노드A, 노드B, 노드D를 알고 있음
                노드D: 노드A, 노드B, 노드C를 알고 있음

                # 노드A에서 CLUSTER FORGET 노드DID 실행
                redis-cli -h 노드A CLUSTER FORGET 노드DID

                # 결과: 노드A만 노드D를 잊음
                노드A: 노드B, 노드C만 알고 있음 (노드D 제거됨)
                노드B: 여전히 노드A, 노드C, 노드D를 알고 있음
                노드C: 여전히 노드A, 노드B, 노드D를 알고 있음
                노드D: 여전히 노드A, 노드B, 노드C를 알고 있음
                ```
            - 자기 자신은 forget 불가
            - 슬롯을 가진 노드는 forget 진행 시 에러 발생 위험
                ```bash
                # 노드D가 슬롯 0-5460을 담당 중
                redis-cli -h 노드A CLUSTER FORGET 노드DID
                # 실행은 되지만 클러스터 문제 발생!

                # 슬롯 0-5460에 대한 정보 손실
                # 해당 슬롯 접근 시 CLUSTERDOWN 발생 가능
                ```
            - 60초의 재연결 차단
                + 클러스터 구성에서 각 노드들은 가십 프로토콜을 이용해 통신하고 신규 클러스터 노드가 감지되면 자동으로 추가한다
                + 따라서 60초동안 재연결을 거부한다
        + cluster reset
            - soft와 hard의 두가지 옵션이 있다(기본값 soft)
            - redis-cli cluster reset soft
                ```bash
                redis-cli CLUSTER RESET SOFT

                # 동작:
                # - 다른 노드들 정보 삭제
                # - 자신의 노드 ID 유지
                # - 데이터는 유지
                # - configEpoch 초기화
                ```
            - redis-cli cluster reset hard
                ```bash
                redis-cli CLUSTER RESET HARD

                # 동작:
                # - 클러스터 구성에서 복제본이었으면 마스터로 전환, 
                # - 자신의 노드 ID 재생성 (새 ID)
                # - 데이터는 유지
                # - configEpoch, currentEpoch, lastVoteEpoch 값 초기화
                # - 완전히 새로운 노드처럼 시작
                ```
            - cluster del-node 진행 중 자동으로도 실행되지만 개발자가 특정 클러스터 노드를 다른 역할로 재활용하고자 할때 수동으로 진행이 가능
        + cluster forget과 cluster reset 비교
            - cluster reset
                + 대상 : 커맨드를 실행한 자기 자신
                + 역할
                    - 노드가 가지고 있던 클러스터 메타데이터(노드 목록, 슬롯 매핑, 설정 등)을 모두 초기화
                    - 클러스터에서 새로운 노드처럼 리셋하는 효과
                    - 두가지 리셋 옵션이 존재
                        + cluster reset soft : 클러스터 설정을 리셋하지만 노드 ID는 유지
                        + cluster reset hard : 클러스터 설정과 노드 ID도 리셋(사실상 새 노드 취급)
                + 상황
                    - 노드를 기존 클러스터에서 제거하고 새 클러스터에 추가할 때
                    - 잘못 설정한 클러스터 노드를 리셋하고 재설정하고 싶을 때
            - cluster forget <node-id>
                + 대상 : 명령을 실행한 노드와 연결된 다른 노드
                + 역할
                    - 해당 노드의 메타데이터(슬롯 정보, 상태 등)을 삭제하라 지시
                    - 자기 자신은 리셋되지 않음, 클러스터 연결 정보는 계속 유지
                    - 다른 노드들도 해당 노드 정보를 전파받아 클러스터 정보에서 삭제


            | 명령어 | 적용 대상    | 효과   | 대표적 사용 상황          |
            | ------------------ | -------- | ------------------------------ | ------------------ |
            | **CLUSTER RESET**  | 자기 자신    | 클러스터 메타데이터 초기화 (노드 ID까지 리셋 가능) | 새 클러스터 합류용, 노드 재설정 |
            | **CLUSTER FORGET** | 특정 다른 노드 | 해당 노드만 클러스터 뷰에서 제거             | 장애 노드 제거, 멤버십 관리   |
